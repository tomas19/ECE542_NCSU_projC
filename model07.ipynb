{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomas/miniconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import copy\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data as a dictionary with each subject as a different key\n",
    "## the sessions are included as a column in each dataframe\n",
    "pathData = Path(r'./TrainingData')\n",
    "dctData = read_data(pathData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## upsample labels using nearest neighbor\n",
    "dctUps = upsampleData(dctData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count number of timesteps for each session and subject\n",
    "dctClass = {f'subject_{k+1}':pd.DataFrame(index = range(1, 9), columns = range(0, 4), data = 0) for k in range(8)}\n",
    "for k in dctUps.keys():\n",
    "    dfs = dctUps[k]\n",
    "    for s in dfs['session'].unique():\n",
    "        dfss = dfs[dfs['session'] == s]\n",
    "        aux = dfss['class'].value_counts().sort_index()\n",
    "        dctClass[k].loc[s, aux.index] = aux.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the number of instances for each to make the dataset balanced\n",
    "## the first and second more frequents per session and individual are set to two times\n",
    "## the third class in case they are larger. The mode is set as the same of the second \n",
    "## more repeated class\n",
    "dctClassBal = balanceData(dctClass, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomly select values for the 2 mode classes to match the dctClassBal\n",
    "dctUpsBal = {}\n",
    "for k in dctUps.keys():\n",
    "    dfk =  dctUps[k]\n",
    "    out2 = []\n",
    "    for s in dfk['session'].unique():\n",
    "        dfks = dfk[dfk['session'] == s]\n",
    "\n",
    "        nvalAll = dctClass[k].loc[s, :]\n",
    "        nvalBall = dctClassBal[k].loc[s, :]\n",
    "        \n",
    "        out = []\n",
    "        for c in nvalAll.index:\n",
    "            dfksc = dfks[dfks['class'] == c]\n",
    "            dfkscBal = dfks.sample(nvalBall.loc[c]).sort_index()\n",
    "            out.append(dfkscBal)\n",
    "        dfout = pd.concat(out).sort_index()\n",
    "        out2.append(dfout)\n",
    "    dctUpsBal[k] = pd.concat(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['accx', 'accy', 'accz', 'gyrox', 'gyroy', 'gyroz', 'class']\n",
    "dfX, dfy = [], []\n",
    "for k in dctUpsBal.keys():\n",
    "    dfk = dctUpsBal[k].loc[:, cols]\n",
    "    dfk['subject'] = [k]*len(dfk)\n",
    "    dfy.append(dfk.loc[:, 'class'].values)\n",
    "    dfk = dfk.drop(['class'], axis = 1)\n",
    "    dfX.append(dfk.values)\n",
    "dfX = pd.DataFrame(columns = dfk.columns, data = np.concatenate(dfX, axis = 0))\n",
    "dfy = pd.DataFrame(columns = ['class'], data = np.concatenate(dfy, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()    \n",
    "    self.cnn1 = nn.Conv1d(6, 24, 9, stride = 1, padding = 4)\n",
    "    self.bn1 = nn.BatchNorm1d(num_features = 24)\n",
    "    self.avPool1 = nn.AvgPool1d(5, stride = 1, padding = 2)\n",
    "\n",
    "    self.cnn2 = nn.Conv1d(24, 48, 7, stride = 1, padding = 3)\n",
    "    self.bn2 = nn.BatchNorm1d(num_features = 48)\n",
    "    self.avPool2 = nn.AvgPool1d(3, stride = 1, padding = 1)\n",
    "    \n",
    "    self.lin1 = nn.Linear(in_features = 1200, out_features = 600)\n",
    "    self.bn3 = nn.BatchNorm1d(num_features = 600)\n",
    "    self.lin2 = nn.Linear(in_features = 600, out_features = 200)\n",
    "    self.bn4 = nn.BatchNorm1d(num_features = 200)\n",
    "    self.lin3 = nn.Linear(in_features = 200, out_features = 100)\n",
    "    self.bn5 = nn.BatchNorm1d(num_features = 100)\n",
    "    self.lin4 = nn.Linear(in_features = 100, out_features = 40)\n",
    "    self.bn6 = nn.BatchNorm1d(num_features = 40)\n",
    "    self.lin5 = nn.Linear(in_features = 40, out_features = 4)\n",
    "\n",
    "    self.dout = nn.Dropout(p=0.4)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.cnn1(x)\n",
    "    # print(f'cnn 1: {x.shape}')\n",
    "    x = self.bn1(x)\n",
    "    # print(f'bn 1: {x.shape}')\n",
    "    x = F.relu(x)\n",
    "    x = self.avPool1(x)\n",
    "    # print(f'av pool 1: {x.shape}')\n",
    "\n",
    "    x = self.cnn2(x)\n",
    "    # print(f'cnn 2: {x.shape}')\n",
    "    x = self.bn2(x)\n",
    "    # print(f'bn 1: {x.shape}')\n",
    "    x = F.relu(x)\n",
    "    x = self.avPool2(x)\n",
    "    # print(f'av pool 2: {x.shape}')\n",
    "\n",
    "    x = x.flatten(start_dim = 1)\n",
    "    # print(f'shape after flatten: {x.shape}')\n",
    "    \n",
    "    x = self.lin1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn3(x)\n",
    "    x = self.dout(x)\n",
    "\n",
    "    x = self.lin2(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn4(x)\n",
    "    x = self.dout(x)\n",
    "\n",
    "    x = self.lin3(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn5(x)\n",
    "    x = self.dout(x)\n",
    "\n",
    "    x = self.lin4(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn6(x)\n",
    "    x = self.dout(x)\n",
    "\n",
    "    x = self.lin5(x)\n",
    "    x = F.softmax(x, dim = 1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a wrapper so we have the same interface for all the methods\n",
    "class NetWrapper:\n",
    "  def __init__(self, epochs, lrate, dev, w):\n",
    "    self.model = Net()\n",
    "    if w != None:\n",
    "      self.loss = nn.CrossEntropyLoss(w)\n",
    "    else:\n",
    "      self.loss = nn.CrossEntropyLoss()\n",
    "      \n",
    "    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lrate)\n",
    "    self.device = dev\n",
    "    self.model.to(self.device)\n",
    "    self.epochs = epochs\n",
    "    self.history = {'train_loss': [], 'val_loss': [],\n",
    "                    'train_accuracy': [], 'val_accuracy': []}\n",
    "    self.accuracy = []\n",
    "    self.min_loss = np.inf\n",
    "    self.best_weights = None\n",
    "\n",
    "  def accuracyFx(self, predVals, trueVals):\n",
    "    predVals = predVals.cpu().detach().numpy()\n",
    "    trueVals = trueVals.cpu().detach().numpy()\n",
    "    correct = np.sum(np.array(predVals == trueVals)).item()\n",
    "    total = trueVals.shape[0]\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "  def fit(self, tloader, vloader):\n",
    "    \n",
    "    for t in range(self.epochs):\n",
    "\n",
    "        ########### Training\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        lossL, accL = [], []\n",
    "        for b, (Xtrb, ytrb) in enumerate(tloader):\n",
    "          Xtrb = Xtrb.permute(0, 2, 1).to(self.device)\n",
    "          ytrb = ytrb.squeeze(2)\n",
    "          ytrb, _ = torch.mode(ytrb, dim = 1)\n",
    "          ytrb = ytrb.to(self.device)\n",
    "          # print(f'ytrb shape: {ytrb.shape}')\n",
    "          yPred = self.model(Xtrb)\n",
    "          ## compute loss\n",
    "          loss = self.loss(yPred, ytrb)\n",
    "          loss_val = float(loss.cpu().detach().numpy())\n",
    "          # print(loss_val)\n",
    "          ## compute accuracy\n",
    "          acc_val = self.accuracyFx(yPred, ytrb)\n",
    "          ## backward propagation\n",
    "          loss.backward()\n",
    "          self.optimizer.step()\n",
    "          lossL.append(loss_val)\n",
    "          accL.append(acc_val)\n",
    "\n",
    "        self.history[r'train_loss'].append(np.mean(lossL))\n",
    "        self.history[r'train_accuracy'].append(np.mean(accL))\n",
    "          \n",
    "        ########### Evaluation\n",
    "        self.model.eval()\n",
    "        lossL, accL = [], []\n",
    "        for b, (Xvalb, yvalb) in enumerate(vloader):\n",
    "          Xvalb = Xvalb.permute(0, 2, 1).to(self.device)\n",
    "          yvalb = yvalb.squeeze(2)\n",
    "          yvalb, _ = torch.mode(yvalb, dim = 1)\n",
    "          yvalb = yvalb.to(self.device)\n",
    "          yPred = self.model(Xvalb)\n",
    "          ## compute loss\n",
    "          loss = self.loss(yPred, yvalb)\n",
    "          loss_val = float(loss.cpu().detach().numpy())\n",
    "          ## compute accuracy\n",
    "          acc_val = self.accuracyFx(yPred, yvalb)\n",
    "          lossL.append(loss_val)\n",
    "          accL.append(acc_val)\n",
    "\n",
    "        self.history[r'val_loss'].append(np.mean(lossL))\n",
    "        self.history[r'val_accuracy'].append(np.mean(accL))\n",
    "\n",
    "        if loss < self.min_loss:\n",
    "          self.min_loss = loss\n",
    "          self.best_weights = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "        if t%100 == 0:\n",
    "          a = self.history[f'train_loss'][t]\n",
    "          b = self.history[f'val_loss'][t]\n",
    "          c = self.history[f'train_accuracy'][t]\n",
    "          d = self.history[f'val_accuracy'][t]\n",
    "        \n",
    "          print(f'Epoch {t}/{self.epochs}. Training loss: {a:0.3f} - Validation loss: {b:0.3f} Training accuracy: {c:0.3f} - Validation accuracy: {d:0.3f}')\n",
    "    \n",
    "    dfhist = pd.DataFrame.from_dict(self.history)\n",
    "\n",
    "    return dfhist, self.min_loss, self.best_weights\n",
    "\n",
    "  def predict(self, X):\n",
    "    # X = torch.from_numpy(X).float()\n",
    "    # print(X.shape)\n",
    "    X = X.to(self.device)\n",
    "    pred = self.model(X)\n",
    "    pred = pred.cpu().detach().numpy()\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "kVal = 'subject_1'\n",
    "\n",
    "dfXtr = dfX[dfX['subject'] != kVal]\n",
    "dfytr = dfy.loc[dfXtr.index, :]\n",
    "\n",
    "dfXvl = dfX[dfX['subject'] == kVal]\n",
    "dfyvl = dfy.loc[dfXvl.index, :]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr_sc = scaler.fit_transform(dfXtr.iloc[:, :-1])\n",
    "Xvl_sc = scaler.transform(dfXvl.iloc[:, :-1])\n",
    "\n",
    "Xtr = torch.tensor(Xtr_sc.astype('float32'))\n",
    "ytr = torch.tensor(dfytr.values.astype('int64'))\n",
    "\n",
    "Xvl = torch.tensor(Xvl_sc.astype('float32'))\n",
    "yvl = torch.tensor(dfyvl.values.astype('int64'))\n",
    "\n",
    "seq_len = 25 # length of each sequence\n",
    "overlap = 5 # overlapping between sequences\n",
    "tr_sequences = []\n",
    "vl_sequences = []\n",
    "\n",
    "# create sequences for training data\n",
    "for i in range(0, len(Xtr)-seq_len, overlap):\n",
    "    seq_X = Xtr[i:i+seq_len]\n",
    "    seq_y = ytr[i:i+seq_len]\n",
    "    tr_sequences.append((seq_X, seq_y))\n",
    "\n",
    "# create sequences for validation data\n",
    "for i in range(0, len(Xvl)-seq_len, overlap):\n",
    "    seq_X = Xvl[i:i+seq_len]\n",
    "    seq_y = yvl[i:i+seq_len]\n",
    "    vl_sequences.append((seq_X, seq_y))\n",
    "\n",
    "bsize = 18000\n",
    "trLoader = DataLoader(tr_sequences, batch_size = bsize, shuffle = False)\n",
    "vlLoader = DataLoader(vl_sequences, batch_size = bsize, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10. Training loss: 1.392 - Validation loss: 1.386 Training accuracy: 0.000 - Validation accuracy: 0.000\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 1e-4\n",
    "\n",
    "net = NetWrapper(10, learning_rate, device, None)\n",
    "dfhist, minLoss, bestModel = net.fit(trLoader, vlLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.395063</td>\n",
       "      <td>1.388191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.385362</td>\n",
       "      <td>1.389966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.378054</td>\n",
       "      <td>1.391288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.371159</td>\n",
       "      <td>1.391719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.365483</td>\n",
       "      <td>1.390441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.359258</td>\n",
       "      <td>1.386188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.352307</td>\n",
       "      <td>1.377164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.345314</td>\n",
       "      <td>1.361720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.337280</td>\n",
       "      <td>1.340153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.330467</td>\n",
       "      <td>1.315932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  val_loss  train_accuracy  val_accuracy\n",
       "0    1.395063  1.388191             0.0           0.0\n",
       "1    1.385362  1.389966             0.0           0.0\n",
       "2    1.378054  1.391288             0.0           0.0\n",
       "3    1.371159  1.391719             0.0           0.0\n",
       "4    1.365483  1.390441             0.0           0.0\n",
       "5    1.359258  1.386188             0.0           0.0\n",
       "6    1.352307  1.377164             0.0           0.0\n",
       "7    1.345314  1.361720             0.0           0.0\n",
       "8    1.337280  1.340153             0.0           0.0\n",
       "9    1.330467  1.315932             0.0           0.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfhist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.7760e-01,  2.5525e-02, -5.5269e-01,  2.0498e-03, -4.8640e-02,\n",
       "          9.1563e-02],\n",
       "        [ 6.3349e-01,  4.7931e-02, -5.6494e-01, -6.1872e-04, -2.4968e-02,\n",
       "          1.0883e-01],\n",
       "        [ 7.5112e-01,  5.8072e-02, -5.6630e-01,  6.3357e-03, -2.9194e-02,\n",
       "          9.4812e-02],\n",
       "        ...,\n",
       "        [-7.5513e-02,  1.4974e-01, -4.2779e-01,  4.6454e-02,  4.4187e-02,\n",
       "          1.0860e-01],\n",
       "        [-3.6501e-01,  2.1788e-01, -3.7248e-01,  2.0276e-02, -5.7532e-02,\n",
       "          4.6427e-02],\n",
       "        [-3.4980e-01,  1.6202e-01, -3.8514e-01, -2.0912e-03,  9.3339e-03,\n",
       "          7.5655e-02]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([134308, 6])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xvl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [24, 6, 9], expected input[1, 134308, 6] to have 6 channels, but got 134308 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mpredict(Xvl)\u001b[39m#.argmax(axis = 1)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[159], line 99\u001b[0m, in \u001b[0;36mNetWrapper.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     96\u001b[0m   \u001b[39m# X = torch.from_numpy(X).float()\u001b[39;00m\n\u001b[1;32m     97\u001b[0m   \u001b[39m# print(X.shape)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m   X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 99\u001b[0m   pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(X)\n\u001b[1;32m    100\u001b[0m   pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    102\u001b[0m   \u001b[39mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[119], line 25\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 25\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn1(x)\n\u001b[1;32m     26\u001b[0m   \u001b[39m# print(f'cnn 1: {x.shape}')\u001b[39;00m\n\u001b[1;32m     27\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [24, 6, 9], expected input[1, 134308, 6] to have 6 channels, but got 134308 channels instead"
     ]
    }
   ],
   "source": [
    "pred = net.predict(Xvl)#.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mpredict(Xvl_sc)\u001b[39m.\u001b[39margmax(axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m m \u001b[39m=\u001b[39m confusion_matrix(yvl\u001b[39m.\u001b[39mvalues, pred)\n\u001b[1;32m      3\u001b[0m disp \u001b[39m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[39m=\u001b[39mm)\n",
      "Cell \u001b[0;32mIn[144], line 97\u001b[0m, in \u001b[0;36mNetWrapper.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     96\u001b[0m   X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(X)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 97\u001b[0m   X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mpermute(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     98\u001b[0m   pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(X)\n\u001b[1;32m     99\u001b[0m   pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "\n",
    "m = confusion_matrix(yvl.values, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=m)\n",
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "disp.plot(ax = ax,  cmap = plt.cm.Blues)\n",
    "ax.set_title(f\"F1 score leaving subject {i} out: {f1_score(pred, yvl.values, average='macro'):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble the models in case we decide to go with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['subject_1', 'subject_2', 'subject_3', 'subject_4', 'subject_5', 'subject_6', 'subject_7', 'subject_8'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ensemble_predict(inputs):\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        # get the predictions of each individual model\n",
    "        outputs.append(model1(inputs))\n",
    "        outputs.append(model2(inputs))\n",
    "        outputs.append(model3(inputs))\n",
    "        outputs.append(model4(inputs))\n",
    "        outputs.append(model5(inputs))\n",
    "        outputs.append(model6(inputs))\n",
    "        outputs.append(model7(inputs))\n",
    "        outputs.append(model8(inputs))\n",
    "        \n",
    "        # take the average of the outputs\n",
    "        outputs = torch.stack(outputs).mean(dim=0)\n",
    "        \n",
    "        # return the class with the highest probability\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
